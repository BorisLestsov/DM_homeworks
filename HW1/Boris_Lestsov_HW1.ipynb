{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 1. Сбор данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При решении реальных задач мы почти никогда не имеем дело с \"хорошими\" исходными данными, уже подготовленными для обработки и анализа. Как правило на входе имеются неструкткрированные данные в \"грязном\" виде, например необработанные тексты, изображения или аудио файлы. Иногда нет даже этого, и данные приходится собирать из разных доступных источников: разнообразных баз данных, внешних сервисов и даже электронных таблиц. После того, как данные получены, их унифицируют, очищают от шума, преобразовывают в нужный вид и сохраняют для дальнейшего анализа. В одном из традиционных подходов к [Data Mining](http://www.wikiwand.com/en/Online_analytical_processing) этот процесс называется Extract-Transform-Load ([ETL](http://www.wikiwand.com/en/Extract,_transform,_load)).\n",
    "\n",
    "Цель этого задания собрать первые данные о пользователях из обучающей выборки и провести простейший качественный анализ. В ходе решения будут использованы:\n",
    "1. [numpy](http://www.numpy.org/) -- библиотека для работы с многомерными массивами\n",
    "2. [pandas](http://pandas.pydata.org/) -- библиотека, позволяющая удобно работать с различными типами данных\n",
    "3. [requests](http://docs.python-requests.org/en/latest/) -- библиотека, которую можно использовать для вызова HTTP запросов\n",
    "4. [python-twitter](https://github.com/bear/python-twitter/tree/master/twitter) -- обертка для Twitter API\n",
    "5. [matplotlib](http://matplotlib.org/) -- библиотека для рисования графиков в python\n",
    "\n",
    "Первым делом импортируем необходимые библиотеки и убеждаемся, что все установлено."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import mpl_toolkits.basemap as bm\n",
    "import twitter\n",
    "import requests\n",
    "import datetime\n",
    "import dateutil\n",
    "import csv\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Plotting config\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чтение исходных данных из файла"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считываем исходные данные из файла в data frame библиотеки pandas. Полученный data frame должен иметь целочисленный ключ и две колонки:\n",
    "1. uid -- идентификатор пользователя\n",
    "2. cat -- числовой номер класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAINING_SET_PATH = \"train.csv\"\n",
    "TESTING_SET_PATH = \"test.csv\"\n",
    "df_users_train = pd.read_csv(TRAINING_SET_PATH, sep=\",\", header=0)\n",
    "df_users_ex = pd.read_csv(TESTING_SET_PATH, sep=\",\", header=0)\n",
    "df_users_ex['cls'] = None\n",
    "df_users = pd.concat([df_users_train, df_users_ex])\n",
    "df_users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим распределение целевой переменной. Требуется получить [barchart](http://www.wikiwand.com/en/Bar_chart), в котором высота столбика, соответствующего каждому из классов, пропорциональна количеству пользователей этого класса. По горизонтальной оси отложены классы (positive, negative), а по вертикальной -- количество пользователей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute the distribution of the target variable\n",
    "counts, bins = np.histogram(df_users_train[\"cls\"], bins=[0,1,2])\n",
    "\n",
    "# Plot the distribution\n",
    "pl.figure(figsize=(6,6))\n",
    "pl.bar(bins[:-1], counts, width=0.5, alpha=0.4)\n",
    "pl.xticks(bins[:-1] + 0.3, [\"negative\", \"positive\"])\n",
    "pl.xlim(bins[0] - 0.5, bins[-1])\n",
    "pl.ylabel(\"Number of users\")\n",
    "pl.title(\"Target variable distribution\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сбор данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того чтобы разработать модель, которая предсказывает значение целевой переменной для произвольного пользователя, недостаточно знать только значения идентификаторов пользоватей. Причина в том, что _user_id_ для пользователя никак не зависит от целевой переменной -- идентификатор генерируется на основании времени регистрации, сервера, обрабатывающего запрос, и номера пользователя ([подробности](https://dev.twitter.com/overview/api/twitter-ids-json-and-snowflake)).\n",
    "\n",
    "Поэтому нам потребуется загрузить дополнительную информацию о каждом пользователе, иначе говоря провести сбор данных (data collection). Наиболее важную информацию можно загрузить из [Twitter](https://dev.twitter.com/rest/public) [API](http://www.wikiwand.com/en/Representational_state_transfer). При желании можно воспользоваться и другими источниками -- об этом ниже.\n",
    "\n",
    "Для того, чтобы получить доступ к API прежде всего необходимо зарегистрироваться в Twitter в качестве разработчика и создать свое [приложение](https://apps.twitter.com/). После создания приложения будет доступен набор ключей, которые мы будем использовать для аутентификации. Эти ключи необходимо скопировать в соответствующие константы ниже. Подробнее о том, как работает аутентификация в Twitter API можно почитать [по ссылке](https://dev.twitter.com/oauth/application-only), хотя это нужно скорее для ознакомления: библиотека обращения с API позаботится о механизме аутентификации за нас."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'twitter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-bc77a895d7dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mACCESS_TOKEN_SECRET\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"ytkVIVabGuR3wu7yb0WB3HqSG7M2ARdeqVMGsEOFQr8m4\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m api = twitter.Api(consumer_key=CONSUMER_KEY, \n\u001b[0m\u001b[0;32m      8\u001b[0m                   \u001b[0mconsumer_secret\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCONSUMER_SECRET\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                   \u001b[0maccess_token_key\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mACCESS_TOKEN_KEY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'twitter' is not defined"
     ]
    }
   ],
   "source": [
    "CONSUMER_KEY = \"BZjjEtEaD2ulm5csczTOa85jn\"\n",
    "CONSUMER_SECRET = \"DBAQdNulMuaNc4LImSO7Pmhu0l6B4NbTcJraNmvUsMJH7nmXB4\"\n",
    "\n",
    "ACCESS_TOKEN_KEY = \"781148741701099520-KwibHnGrl8PW9UyOHY91j5p9uSJub6T\"\n",
    "ACCESS_TOKEN_SECRET = \"ytkVIVabGuR3wu7yb0WB3HqSG7M2ARdeqVMGsEOFQr8m4\"\n",
    "\n",
    "api = twitter.Api(consumer_key=CONSUMER_KEY, \n",
    "                  consumer_secret=CONSUMER_SECRET, \n",
    "                  access_token_key=ACCESS_TOKEN_KEY, \n",
    "                  access_token_secret=ACCESS_TOKEN_SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter API предоставляет информацию о местонахождении пользователя, но эта информация представлена в текстовом виде, например так:\n",
    "```\n",
    "\"location\": \"San Francisco, CA\"\n",
    "```\n",
    "Такие текстовый описания не слишком удобны для анализа, поэтому наша цель -- получить более структурированную информацию, такую как географические координаты, страна, город и т.д. Для этого удобно использовать геоинформационный сервис, например [GeoNames](http://www.geonames.org/export/web-services.html). Для его использования также необходимо зарегистрироваться, подтвердить регистрацию и включить поддержку API. После этого можно будет посылать запросы для нахождения нужной информации. Например на запрос\n",
    "```\n",
    "http://api.geonames.org/search?q=\"San Francisco, CA\"&maxRows=10&username=demo\n",
    "```\n",
    "возвращается результат,\n",
    "```javascript\n",
    "{\n",
    "    \"totalResultsCount\": 2112,\n",
    "    \"geonames\": [\n",
    "        {\n",
    "            \"countryId\": \"6252001\",\n",
    "            \"adminCode1\": \"CA\",\n",
    "            \"countryName\": \"United States\",\n",
    "            \"fclName\": \"city, village,...\",\n",
    "            \"countryCode\": \"US\",\n",
    "            \"lng\": \"-122.41942\",\n",
    "            \"fcodeName\": \"seat of a second-order administrative division\",\n",
    "            \"toponymName\": \"San Francisco\",\n",
    "            \"fcl\": \"P\",\n",
    "            \"name\": \"San Francisco\",\n",
    "            \"fcode\": \"PPLA2\",\n",
    "            \"geonameId\": 5391959,\n",
    "            \"lat\": \"37.77493\",\n",
    "            \"adminName1\": \"California\",\n",
    "            \"population\": 805235\n",
    "        },\n",
    "        {\n",
    "            \"countryId\": \"6252001\",\n",
    "            \"adminCode1\": \"CA\",\n",
    "            \"countryName\": \"United States\",\n",
    "            \"fclName\": \"spot, building, farm\",\n",
    "            \"countryCode\": \"US\",\n",
    "            \"lng\": \"-122.3758\",\n",
    "            \"fcodeName\": \"airport\",\n",
    "            \"toponymName\": \"San Francisco International Airport\",\n",
    "            \"fcl\": \"S\",\n",
    "            \"name\": \"San Francisco International Airport\",\n",
    "            \"fcode\": \"AIRP\",\n",
    "            \"geonameId\": 5391989,\n",
    "            \"lat\": \"37.61882\",\n",
    "            \"adminName1\": \"California\",\n",
    "            \"population\": 0\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "из которого легко извлечь нужную информацию.\n",
    "\n",
    "**Замечание: для запросов необходимо использовать своего пользователя, кроме того количество запросов ограничено 30тыс в день**.\n",
    "\n",
    "Первым делом нам понадобится функция, которая возвращает информацию о местоположении для данного текстового запроса. Требуется реализовать функцию get_coordinates_by_location, принимающую на вход строку с местоположением и возвращает кортеж вида (долгота, широта, город)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from xml.dom.minidom import parseString\n",
    "\n",
    "GEO_USER_NAME = \"blestsov\"\n",
    "\n",
    "def get_coordinates_by_location(location):    \n",
    "    \"\"\"\n",
    "    This function gets geographic coordinates and city name\n",
    "    form external web service GeoNames using 'location' string.\n",
    "    \n",
    "    NOTE: the returned value is FAKE. It's only used to show\n",
    "    NOTE: correct output format.\n",
    "    \"\"\"    \n",
    "    \n",
    "    url = 'http://api.geonames.org/search?q=\"' + location + '\"&maxRows=10&username=' + GEO_USER_NAME\n",
    "\n",
    "    r = requests.post(url)\n",
    "    xml = parseString(r.text.encode('utf-8'))\n",
    "    \n",
    "    try:\n",
    "        name = xml.getElementsByTagName('countryName')\n",
    "        lat  = xml.getElementsByTagName('lat')\n",
    "        lon  = xml.getElementsByTagName('lng')\n",
    "        \n",
    "        if (not name or not lat or not lon):\n",
    "            return (0, 0, u\"Unknown\")\n",
    "        \n",
    "        return float(lat[0].childNodes[0].nodeValue), float(lon[0].childNodes[0].nodeValue), name[0].childNodes[0].nodeValue\n",
    "    except:\n",
    "        return (0, 0, u\"Unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующий шаг -- вызов Twitter API для сбора данных и сохранения их в data frame. После чего data frame c собранными данными совмещается с data frame, содержащим данные исходной обучающей выборки. \n",
    "\n",
    "В этой части задания нужно реализовать функцию `get_user_records`, которая принимает на вход прочитанный из файла `data frame` и возвращает список словарей, каждый из которых представляет данные одного пользователя. Для того, чтобы получить из объекта класса [`User`](https://github.com/bear/python-twitter/blob/master/twitter/user.py) словарь в правильном формате, нужно использовать функцию `twitter_user_to_dataframe_record` (4 балла).\n",
    "\n",
    "Так как скрипт работает существенное время, будем сохранять промежуточный результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ts_parser = lambda date_str: dateutil.parser.parse(date_str) if pd.notnull(date_str) else None\n",
    "\n",
    "user_records = []\n",
    "tmp_file_name = 'tmp_user_records'\n",
    "if os.path.exists(tmp_file_name):\n",
    "    with open(tmp_file_name) as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                user_records.append(json.loads(line))\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "processed_users = set()\n",
    "for r in user_records:\n",
    "    processed_users.add(r['uid'])\n",
    "    \n",
    "f = open(tmp_file_name, 'a+b')\n",
    "            \n",
    "def twitter_user_to_dataframe_record(user):\n",
    "    dt = ts_parser(user.created_at)\n",
    "    record = {\n",
    "        \"uid\": user.id,\n",
    "        \"name\": user.name,\n",
    "        \"screen_name\": user.screen_name,        \n",
    "        \"created_at\": dt.strftime(\"%Y-%m\") if dt else dt,        \n",
    "        \"followers_count\": user.followers_count,\n",
    "        \"friends_count\": user.friends_count,\n",
    "        \"statuses_count\": user.statuses_count,\n",
    "        \"favourites_count\": user.favourites_count,\n",
    "        \"listed_count\": user.listed_count,\n",
    "        \"verified\": user.verified\n",
    "    }\n",
    "    \n",
    "    if user.description is not None and user.description.strip() != \"\":\n",
    "        record[\"description\"] = user.description\n",
    "        \n",
    "    if user.location is not None and user.location.strip() != \"\":\n",
    "        record[\"location\"] = user.location\n",
    "        record[\"lat\"], record[\"lon\"], record[\"country\"] = get_coordinates_by_location(user.location)\n",
    "    \n",
    "    records = []\n",
    "    return record\n",
    "\n",
    "\n",
    "def get_user_records(df):\n",
    "    users = []\n",
    "    for i in xrange(len(df['uid'].values) / 100 + 1):\n",
    "        users += api.UsersLookup(list(df['uid'].values[i*100:i*100 + 100]))\n",
    "        print i,\n",
    "    \n",
    "    records = []\n",
    "    for user in users:\n",
    "        records.append(twitter_user_to_dataframe_record(user))\n",
    "    \n",
    "    with open(\"records\", \"w+b\") as o:\n",
    "        json.dump(records, o)\n",
    "    return records\n",
    "\n",
    "# Maximum number of user IDs returned by Twitter's user lookup\n",
    "user_records = get_user_records(df_users)\n",
    "\n",
    "print \"Creating data frame from loaded data\"\n",
    "df_records = pd.DataFrame(user_records, columns=[\"uid\", \"name\", \"screen_name\", \"description\", \"verified\", \"location\", \"lat\", \"lon\", \"country\", \"created_at\", \"followers_count\", \"friends_count\", \"statuses_count\", \"favourites_count\", \"listed_count\"])\n",
    "print \"Merging data frame with the training set\"\n",
    "df_full = pd.merge(df_users, df_records, on=\"uid\", how=\"left\")\n",
    "print \"Finished building data frame\"\n",
    "\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы лучше понять, как устроена наша обучающая выборка, построим несколько графиков. Сначала построим долю \"положительных\" пользователей в зависимости от дня создания аккаунта. По горизонтальной оси отложим день создания аккаунта, а по вертикальной -- долю \"положительных\" пользователей ([подсказка](http://stroykova.github.io/sphera/l1_1.png)). Необходимо дописать код функции count_users. В функции необходимо посчитать пользователей в каждой группе (1 балл)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_users(grouped):\n",
    "    \"\"\"\n",
    "    Counts number of positive and negative users\n",
    "    created at each date.\n",
    "    \n",
    "    Returns:\n",
    "        count_pos -- 1D numpy array with the counts of positive users created at each date\n",
    "        count_neg -- 1D numpy array with the counts of negative users created at each date\n",
    "        dts -- a list of date strings, e.g. ['2014-10', '2014-11', ...]\n",
    "    \"\"\"\n",
    "    dts = []\n",
    "    count_pos, count_neg = np.zeros(len(grouped)), np.zeros(len(grouped))\n",
    "    \n",
    "    for i, gr in enumerate(grouped):\n",
    "        dts.append(gr[0])\n",
    "        for cls in gr[1]['cls'].values:\n",
    "            if cls == 1:\n",
    "                count_pos[i] += 1\n",
    "            elif cls == 0:\n",
    "                count_neg[i] += 1\n",
    "    \n",
    "    return count_pos, count_neg, dts\n",
    "\n",
    "\n",
    "grouped = df_full.groupby(map(lambda dt: dt if pd.notnull(dt) else \"NA\", df_full[\"created_at\"]))\n",
    "count_pos, count_neg, dts = count_users(grouped)\n",
    "    \n",
    "fraction_pos = count_pos / (count_pos + count_neg + 1e-10)\n",
    "fraction_neg = 1 - fraction_pos\n",
    "\n",
    "sort_ind = np.argsort(dts)\n",
    "    \n",
    "pl.figure(figsize=(20, 3))\n",
    "pl.bar(np.arange(len(dts)), fraction_pos[sort_ind], width=1.0, color='red', alpha=0.6, linewidth=0, label=\"Positive\")\n",
    "pl.bar(np.arange(len(dts)), fraction_neg[sort_ind], bottom=fraction_pos[sort_ind], width=1.0, color='green', alpha=0.6, linewidth=0, label=\"Negative\")\n",
    "pl.xticks(np.arange(len(dts)) + 0.4, sorted(dts), rotation=90)\n",
    "pl.title(\"Class distribution by account creation month\")\n",
    "pl.xlim(0, len(dts))\n",
    "pl.legend()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что доля \"положительных\" аккаунтов в выборке растет с увеличением времени. Посмотрим, где живут пользователи положительной и отрицательной категории. Для этого отметим на карте каждого положительного пользователя красным, а отрицательного -- зеленым цветом ([подсказка](http://stroykova.github.io/sphera/l1_2.png)). Необходимо реализовать функцию plot_points_on_map. В функции необходимо отобразить на карте пользователей из разных классов (2 балла)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pl.figure(figsize=(20,12))\n",
    "\n",
    "m = bm.Basemap(projection='cyl', llcrnrlat=-90, urcrnrlat=90, llcrnrlon=-180, urcrnrlon=180, resolution='c')\n",
    "\n",
    "m.drawcountries(linewidth=0.2)\n",
    "m.fillcontinents(color='lavender', lake_color='#000040')\n",
    "m.drawmapboundary(linewidth=0.2, fill_color='#000040')\n",
    "m.drawparallels(np.arange(-90,90,30),labels=[0,0,0,0], color='white', linewidth=0.5)\n",
    "m.drawmeridians(np.arange(0,360,30),labels=[0,0,0,0], color='white', linewidth=0.5)\n",
    "\n",
    "def plot_points_on_map(df_full):\n",
    "    \"\"\"\n",
    "    Plot points on the map. Be creative.\n",
    "    \"\"\"\n",
    "    for i, pers in df_full.iterrows():\n",
    "        if pers['cls'] == 1:\n",
    "            m.scatter(pers['lon'], pers['lat'], 30, c = \"#FF0000\", alpha = 0.6, zorder=3)\n",
    "        elif pers['cls'] == 0:\n",
    "            m.scatter(pers['lon'], pers['lat'], 30, c = \"#00FF00\", alpha = 0.8, zorder=3)\n",
    "    \n",
    "    return\n",
    "\n",
    "plot_points_on_map(df_full)\n",
    "\n",
    "pl.scatter([],[], 80, c = \"#FF0000\", label = \"Positive\")\n",
    "pl.scatter([],[], 80, c = \"#00FF00\", label = \"Negative\")\n",
    "pl.title(\"Geospatial distribution of twitter users\")\n",
    "pl.legend()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В последней картинке есть проблема: сервис геоинформации определяет координаты с точностью до города, поэтому точки, соответствующте нескольким пользователям, могут накладываться. Предложите и реализуйте способ, позволяющий справиться с этой проблемой (2 балла).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В поле ниже необходимо словами описать, как было улучшено изображение (описание необходимо для корректной проверки задания)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На изображении сделаны следующие улучшения:\n",
    "* Добавлена прозрачность, поэтому теперь точки не перекрывают друг полностью\n",
    "* Точки, соответствующие \"негативным\" пользователям (зеленые) имеют меньшую прозрачность, так как их меньше, поэтому они сильнее выделяются\n",
    "* Размер точек подобран так, чтобы точки не сильно перекрывали друг друга, и в тоже время единичные точки были хорошо различимы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Опредилим пользователи какого класса популярнее, а именно пользователи какого класса имеют больше фолловеров. \n",
    "\n",
    "Для этого\n",
    "    1. Посчитайте дескриптивные статистики для признака followers_count -- min, max, mean и median \n",
    "    2. Постройте гистограммы для пользователей двух классов.\n",
    "[подсказка](http://stroykova.github.io/sphera/l1_3.png) \n",
    "    3. На основе полученных данных ответьте на вопросы \n",
    "        1. Почему mean и median имеют разные значения?\n",
    "        2. Пользователи какого класса популярнее? Аргументируйте ответ.\n",
    "Подсказка: так как пользователей позитивного класса в 3.5 раза больше, чем негативного прежде чем приступать к анализу необходимо случайным образом выбрать по N(N>=500) пользователей негативного и позитивного классов. (1 балл)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_number = 500\n",
    "users_wth_neg_class = df_full[df_full[\"cls\"]==0].sample(sample_number)\n",
    "users_wth_pos_class = df_full[df_full[\"cls\"]==1].sample(sample_number)\n",
    "\n",
    "def descriptive_stat_and_hist(users_wth_neg_class, users_wth_pos_class):\n",
    "\n",
    "        #Calculate min max and median. Plot histogram\n",
    "        #Your code here\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Смотрим на полученный data frame и сохраняем его в .csv файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUT_FILE_PATH = \"hw1_out.csv\"\n",
    "print \"Saving output data frame to %s\" % OUT_FILE_PATH\n",
    "df_full.to_csv(OUT_FILE_PATH, sep=\"\\t\", index=False, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC)\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
